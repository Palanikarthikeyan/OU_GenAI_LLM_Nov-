{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17eaf8a-f043-4375-83b0-631698db49c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p101': 'pA', 'p102': 'pB', 'p103': 'pC'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores = {}\n",
    "stores['p101'] = 'pA'\n",
    "stores['p102'] = 'pB'\n",
    "stores['p103'] = 'pC'\n",
    "\n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d348e38f-c40f-4a7f-8f5d-fa80d76e46d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p101': ['pA', 1000, 'pVendor1'], 'p102': ['pB', 2000, 'pVendor2']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores = {}\n",
    "stores ['p101'] = ['pA',1000,'pVendor1']\n",
    "stores ['p102'] = ['pB',2000,'pVendor2']\n",
    "\n",
    "stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cf0b96-bd23-4d22-bf39-d4d1fda6bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pB', 2000, 'pVendor2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores['p102']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b91b93-0736-49cf-88a1-8a8e8cdb7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatMessageHistory - stores messages (Human + AI )\n",
    "|\n",
    "BaseChatMessageHistory - Abstract base class(interface) \n",
    "|\n",
    "RunnableWithMessageHistory - Langchain wrapper - combines an LLM with messagehistory \n",
    "-----------------------------//\n",
    "\n",
    "stores ={\n",
    "    \"session_1\" : ChatMessageHistory(),\n",
    "    \"session_2\" : ChatMessageHistory(),\n",
    "     ...\n",
    "}\n",
    "def user_defined_function(session_id:str) -> BaseChatMessageHistory:\n",
    "      if session_id not in stores:\n",
    "          stores[session_id] = ChatMessageHistory()\n",
    "      return stores[session_id]\n",
    "\n",
    "obj = RunnableWithMessageHistory(llm_obj,user_defined_function)\n",
    "\n",
    "obj.invoke({'message':[role],config={\"configurable\":{\"session_id\":<sessionID>}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bd1ab-fc89-4ad7-8002-0ab3a91e6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "User_Q: What is python\n",
    "AI_R: .....\n",
    "User_Q: give me any 5 features\n",
    "AI_R: there are 5 import python features\n",
    "----------------\n",
    "User_Q1: Hello my name is Tom\n",
    "AI_ Hello Tom ..my name is userA......\n",
    "User_Q2: renewal my website domain\n",
    "AI  Tom ...type your website domain\n",
    "User_Q2:\n",
    "-----------------------------------//session expired \n",
    "User_Q1: I will type website name?\n",
    "AI_ may i know ...\n",
    "...\n",
    "--------------------------------------//session expired\n",
    "\n",
    " +------------------------------------------+\n",
    " | sessionID        |    chat(Human+AI)     |\n",
    " +------------------+-----------------------+\n",
    " |   Session1       | User_Q: What is python \n",
    "                      AI_R: .....\n",
    "                      User_Q: give me any 5 features\n",
    "                      AI_R: there are 5 import python features\n",
    " |------------------------------------------+\n",
    " |   Session2:      |  User_Q1: Hello my name is Tom\n",
    "                    |  AI_ Hello Tom ..my name is userA......\n",
    "                    |  User_Q2: renewal my website domain\n",
    "                    |  AI  Tom ...type your website domain\n",
    " |\n",
    " |------------------|-----------------------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9759f7ce-b30a-40b4-9c0a-7846dc755a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a943cc-7878-4f15-8abe-20b2c6bfd350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da51d81c-4fa0-4297-a25b-c433a6be9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb3370e-74f3-4997-b57e-c394fff523d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_obj = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "809853bf-4387-4c50-9b91-abc673b1b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = {}\n",
    "def get_session_history(session_id: str) ->BaseChatMessageHistory:\n",
    "    if session_id not in stores:\n",
    "        stores[session_id] = ChatMessageHistory()\n",
    "    return stores[session_id]\n",
    "\n",
    "msg_history = RunnableWithMessageHistory(llm_obj,get_session_history)\n",
    "my_config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "285c07eb-2a6f-4073-8f40-b74620fd7d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Tom, it's nice to meet you. Is there anything I can help you with or would you like to chat?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 41, 'total_tokens': 67, 'completion_time': 0.029467624, 'prompt_time': 0.001960013, 'queue_time': 0.054479717, 'total_time': 0.031427637}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--a6eb2840-6c7e-4ebb-a3e1-4e7009decdc0-0' usage_metadata={'input_tokens': 41, 'output_tokens': 26, 'total_tokens': 67}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response = msg_history.invoke([HumanMessage(content=\"Hello, My name is Tom\")],config=my_config)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a346f4-aebe-45c4-87bd-4b5d3dd4ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Tom, it's nice to meet you. Is there anything I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b027da-c3bb-4f3c-9e3b-b45bd12f99ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As I mentioned earlier, I don't have any information about your personal details. You haven't shared your name with me, and I don't retain any information from previous conversations.\n",
      "\n",
      "If you'd like to introduce yourself, I'd be happy to chat with you and address you by your chosen name.\n"
     ]
    }
   ],
   "source": [
    "my_config = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = msg_history.invoke([HumanMessage(content=\"What is my name\")],config=my_config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80cf03d3-e457-4ba7-85d3-0c0e3c516c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Tom.\n"
     ]
    }
   ],
   "source": [
    "my_config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response = msg_history.invoke([HumanMessage(content=\"What is my name\")],config=my_config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "401328d6-2882-4bc0-8949-eade902ccd45",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sample Python Program: A Simple Calculator**\n",
      "=====================================================\n",
      "\n",
      "Here's a simple example of a Python program that acts as a basic calculator. This program will take an operation and two numbers as input from the user and then perform the operation.\n",
      "\n",
      "### Code\n",
      "```python\n",
      "# Import the necessary module for getting user input\n",
      "import operator\n",
      "\n",
      "# Define a dictionary that maps operations to their corresponding functions\n",
      "operations = {\n",
      "    '+': operator.add,\n",
      "    '-': operator.sub,\n",
      "    '*': operator.mul,\n",
      "    '/': operator.truediv\n",
      "}\n",
      "\n",
      "def calculator():\n",
      "    # Get the operation from the user\n",
      "    print(\"Available operations:\")\n",
      "    print(\"+ for addition\")\n",
      "    print(\"- for subtraction\")\n",
      "    print(\"* for multiplication\")\n",
      "    print(\"/ for division\")\n",
      "    op = input(\"Enter the operation: \")\n",
      "\n",
      "    # Check if the operation is valid\n",
      "    if op not in operations:\n",
      "        print(\"Invalid operation. Please try again.\")\n",
      "        return\n",
      "\n",
      "    # Get the two numbers from the user\n",
      "    num1 = float(input(\"Enter the first number: \"))\n",
      "    num2 = float(input(\"Enter the second number: \"))\n",
      "\n",
      "    # Perform the operation\n",
      "    try:\n",
      "        result = operations[op](num1, num2)\n",
      "        print(f\"{num1} {op} {num2} = {result}\")\n",
      "    except ZeroDivisionError:\n",
      "        print(\"Error: Division by zero is not allowed.\")\n",
      "\n",
      "# Run the calculator\n",
      "calculator()\n",
      "```\n",
      "\n",
      "### Explanation\n",
      "\n",
      "1. We import the `operator` module, which provides functions for basic mathematical operations.\n",
      "2. We define a dictionary `operations` that maps operation symbols to their corresponding functions.\n",
      "3. We define a function `calculator()` that will take care of getting user input, performing the operation, and displaying the result.\n",
      "4. Inside the `calculator()` function, we get the operation from the user and check if it's valid.\n",
      "5. We then get the two numbers from the user and perform the operation using the corresponding function from the `operations` dictionary.\n",
      "6. If the operation is division and the second number is zero, we catch the `ZeroDivisionError` and display an error message.\n",
      "7. Finally, we call the `calculator()` function to start the program.\n",
      "\n",
      "### Example Use Cases\n",
      "\n",
      "* Run the program and enter `+` as the operation and `10` and `5` as the numbers. The program will display `10 + 5 = 15`.\n",
      "* Run the program and enter `*` as the operation and `10` and `5` as the numbers. The program will display `10 * 5 = 50`.\n",
      "* Run the program and enter `/` as the operation and `10` and `0` as the numbers. The program will display `Error: Division by zero is not allowed.`.\n"
     ]
    }
   ],
   "source": [
    "my_config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response = msg_history.invoke([HumanMessage(content=\"How to write sample python program?\")],config=my_config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9460173e-223d-40af-9ac9-baedc48af1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['chat1', 'chat2', 'chat3'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "stores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d9e3d7d-d0b7-4d61-bc7c-1dde79d42e18",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello, My name is Tom', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Tom, it's nice to meet you. Is there anything I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 41, 'total_tokens': 67, 'completion_time': 0.029467624, 'prompt_time': 0.001960013, 'queue_time': 0.054479717, 'total_time': 0.031427637}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a6eb2840-6c7e-4ebb-a3e1-4e7009decdc0-0', usage_metadata={'input_tokens': 41, 'output_tokens': 26, 'total_tokens': 67}), HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Tom.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 80, 'total_tokens': 86, 'completion_time': 0.005235767, 'prompt_time': 0.00468274, 'queue_time': 0.053428459, 'total_time': 0.009918507}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--87289ea0-90fc-4c9f-9fd5-57727cd11fe1-0', usage_metadata={'input_tokens': 80, 'output_tokens': 6, 'total_tokens': 86})])\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(stores['chat1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02a2146d-b174-4dfd-b7f3-21cb898e1826",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq is a company that provides high-performance AI and machine learning (ML) solutions, but I'm assuming you're looking for free LLM (Large Language Model) models, not directly from Groq. Groq doesn't provide free LLM models.\n",
      "\n",
      "However, there are a few alternatives where you can find or train your own free LLM models. Here are a few options:\n",
      "\n",
      "1. **Hugging Face Transformers**: You can download pre-trained models, including LLMs, from the Hugging Face model hub. They also provide a library for fine-tuning and training your own models.\n",
      "2. **Transformers by Facebook AI**: This is another popular library for natural language processing, including LLMs. You can download pre-trained models or train your own models.\n",
      "3. **Google's BERT and ALBERT models**: You can download pre-trained LLM models like BERT and ALBERT from Google's research repository.\n",
      "4. **Microsoft's Turing-NLG model**: This is a large language model developed by Microsoft Research. You can download and use the pre-trained model.\n",
      "5. **Open-source LLM models**: There are several open-source LLM models available on GitHub, such as the \"Big Bird\" model.\n",
      "\n",
      "Keep in mind that these models may not be as powerful as commercial LLMs, like those used by Groq, but they can still be very useful for many NLP tasks.\n",
      "\n",
      "If you're interested in fine-tuning or training your own LLM models, you'll need to have a good understanding of ML concepts, computational resources (e.g., GPU), and software tools like TensorFlow, PyTorch, or Hugging Face Transformers.\n",
      "\n",
      "Let me know if you need more information or help with getting started.\n"
     ]
    }
   ],
   "source": [
    "my_config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response = msg_history.invoke([HumanMessage(content=\"help me to get free llm models from groq\")],config=my_config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "522e16ab-09a4-4736-ab3c-4a420fe96cf6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InMemoryChatMessageHistory(messages=[HumanMessage(content='Hello, My name is Tom', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Tom, it's nice to meet you. Is there anything I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 41, 'total_tokens': 67, 'completion_time': 0.029467624, 'prompt_time': 0.001960013, 'queue_time': 0.054479717, 'total_time': 0.031427637}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a6eb2840-6c7e-4ebb-a3e1-4e7009decdc0-0', usage_metadata={'input_tokens': 41, 'output_tokens': 26, 'total_tokens': 67}), HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Tom.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 80, 'total_tokens': 86, 'completion_time': 0.005235767, 'prompt_time': 0.00468274, 'queue_time': 0.053428459, 'total_time': 0.009918507}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--87289ea0-90fc-4c9f-9fd5-57727cd11fe1-0', usage_metadata={'input_tokens': 80, 'output_tokens': 6, 'total_tokens': 86}), HumanMessage(content='help me to get free llm models from groq', additional_kwargs={}, response_metadata={}), AIMessage(content='Groq is a company that provides high-performance AI and machine learning (ML) solutions, but I\\'m assuming you\\'re looking for free LLM (Large Language Model) models, not directly from Groq. Groq doesn\\'t provide free LLM models.\\n\\nHowever, there are a few alternatives where you can find or train your own free LLM models. Here are a few options:\\n\\n1. **Hugging Face Transformers**: You can download pre-trained models, including LLMs, from the Hugging Face model hub. They also provide a library for fine-tuning and training your own models.\\n2. **Transformers by Facebook AI**: This is another popular library for natural language processing, including LLMs. You can download pre-trained models or train your own models.\\n3. **Google\\'s BERT and ALBERT models**: You can download pre-trained LLM models like BERT and ALBERT from Google\\'s research repository.\\n4. **Microsoft\\'s Turing-NLG model**: This is a large language model developed by Microsoft Research. You can download and use the pre-trained model.\\n5. **Open-source LLM models**: There are several open-source LLM models available on GitHub, such as the \"Big Bird\" model.\\n\\nKeep in mind that these models may not be as powerful as commercial LLMs, like those used by Groq, but they can still be very useful for many NLP tasks.\\n\\nIf you\\'re interested in fine-tuning or training your own LLM models, you\\'ll need to have a good understanding of ML concepts, computational resources (e.g., GPU), and software tools like TensorFlow, PyTorch, or Hugging Face Transformers.\\n\\nLet me know if you need more information or help with getting started.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 354, 'prompt_tokens': 106, 'total_tokens': 460, 'completion_time': 0.610434781, 'prompt_time': 0.006019447, 'queue_time': 0.050785583, 'total_time': 0.616454228}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--20ffa832-776d-4df9-a96e-72190e908e8e-0', usage_metadata={'input_tokens': 106, 'output_tokens': 354, 'total_tokens': 460})])\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(stores['chat1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c7b2f6d-303c-4e34-b04e-c09bbb4f4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chat_history.log','a') as wobj:\n",
    "    for var in stores:\n",
    "        wobj.write(var+str(stores[var])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b9f90bb-b89a-4ae4-a56b-4e716205689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1aaf2ae7-f473-4d8b-8248-85a280d71047",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Your are helpful AI assistant,Answer all the question in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"question\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa575019-69a7-40f1-a9c8-a58a9a39e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|llm_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "968d4327-c64b-4cd5-b54a-ae8607b7a19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bonjour Leo ! Enchanté de faire votre connaissance ! Comment puis-je vous aider aujourd'hui ?\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is leo\")],\"language\":\"french\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35121a2f-6589-4ddd-8b2f-3bf0d50dbf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते लियो! मैं आपकी मदद करने के लिए यहां हूं। क्या मैं आपकी कोई समस्या का समाधान कर सकता हूं या आपके लिए कोई जानकारी प्रदान कर सकता हूं?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is leo\")],\"language\":\"hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77ca9ef7-326a-420a-a7a5-df8622f190d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'హలో లెయో! నేను సహాయక కంప్యూటర్ అసిస్టెంట్. నీవు ఏ సమస్యను లేదా అంశాన్ని పరిష్కరించాలనుకుంటున్నావా?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is leo\")],\"language\":\"telugu\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "012b8606-a3c8-4dfc-b944-26b2b43adb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'வணக்கம் லியோ! நான் உங்களுக்கு உதவ இங்கு இருக்கிறேன். உங்களுக்கு என்ன தேவைப்படுகிறது?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is leo\")],\"language\":\"tamil\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dab26fd-b755-4124-8a6d-9cebd569c0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ನಿಮ್ಮ ಹೆಸರು ಲಿಯೊ. ನಾನು ನಿಮಗಿಡಲು ಸಹಾಯ ಮಾಡಬೇಕಾಗುತ್ತದೆ, ನೀವು ಯಾವ ಸಮಸ್ಯೆಯ ಬಗ್ಗೆ ಪ್ರಶ್ನಿಸುತ್ತೀರೆ?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({'question':[HumanMessage(content=\"Hello my name is leo\")],\"language\":\"kannada\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39215512-5e47-462b-aea8-3a0a51f383d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ನಿಮ್ಮ ಹೆಸರು ಲಿಯೊ. ನಾನು ನಿಮಗಿಡಲು ಸಹಾಯ ಮಾಡಬೇಕಾಗುತ್ತದೆ, ನೀವು ಯಾವ ಸಮಸ್ಯೆಯ ಬಗ್ಗೆ ಪ್ರಶ್ನಿಸುತ್ತೀರೆ?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 160, 'prompt_tokens': 54, 'total_tokens': 214, 'completion_time': 0.21999512, 'prompt_time': 0.002638934, 'queue_time': 0.055482936, 'total_time': 0.222634054}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--133a6fa7-6f1a-4621-9599-f11ccff732a3-0', usage_metadata={'input_tokens': 54, 'output_tokens': 160, 'total_tokens': 214})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1299df-cd8d-448f-98c7-d58564b8c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "Core ideas of prompt engineering\n",
    "|-> llm  - follow the prompt rules and role\n",
    "\n",
    "shots - an example \n",
    "\n",
    "1. zero-shot prompt ==> No examples given\n",
    "Example\n",
    "--------\n",
    "prompt:  \"Translate the following english sentence to french\"\n",
    "         \"I am learning artifical intelligence\"\n",
    "\n",
    "Model output: \".\"Enchanté de faire votre connaissance\"\n",
    "\n",
    "2. one-shot prompt --> One example given\n",
    "prompt:  \"Translate the following english sentence to french\"\n",
    "         French: \"nchanté de faire votre connaissan\"\n",
    "         Now translate:\n",
    "         English: \"I am learning artifical intelligence\"\n",
    "Model output: \".\"Enchanté de faire votre connaissance\"\n",
    "\n",
    "3. few-shot prompt - 2 or 5 exampels (or) more that\n",
    "Prompt:\n",
    "Classify the sentiment of each sentence as Positive,Negative,Neutal\n",
    "\n",
    "Example 1:\n",
    "sentence: The movie was fantastic \n",
    "sentiment: positive\n",
    "Example 2:\n",
    "sentence: The food was not good\n",
    "sentiment: negative\n",
    "Example 3:\n",
    "sentence: It was an average day\n",
    "sentiment: Neutral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f01a4a75-06e8-4cdd-a51e-52f5c6ce4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = ChatPromptTemplate.from_template('''\n",
    "classify the sentiment of the given text as positive,negative or neutral\n",
    "text:{input}\n",
    "Sentiment:''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e02b8270-a5fc-411c-9dea-ed4c35233917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sentiment: Positive\\n\\nThe text contains words and phrases with extremely positive connotations, such as \"I absolutely loved\" and \"fantastic\", indicating a strong positive sentiment towards the movie.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 63, 'total_tokens': 102, 'completion_time': 0.066417411, 'prompt_time': 0.00354582, 'queue_time': 0.05402879, 'total_time': 0.069963231}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--01139dbc-ab6e-4d48-b4bb-f9c35bfe2f14-0', usage_metadata={'input_tokens': 63, 'output_tokens': 39, 'total_tokens': 102})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot = zero_shot_prompt.format_messages(input=\"I absolutely loved the movie, it was fantastic!\")\n",
    "llm_obj.invoke(zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f25bfa6-f78d-434f-aaad-0bdf84cba80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sentiment of the text is Negative.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 61, 'total_tokens': 70, 'completion_time': 0.014569001, 'prompt_time': 0.004444951, 'queue_time': 0.055270859, 'total_time': 0.019013952}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2a70fc44-09ba-433e-8594-b4e124ae6258-0', usage_metadata={'input_tokens': 61, 'output_tokens': 9, 'total_tokens': 70})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot = zero_shot_prompt.format_messages(input=\"I not loved the movie\")\n",
    "llm_obj.invoke(zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89732de0-d226-413a-a0dc-ec40e4a8de06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sentiment: Neutral\\n\\nThe word \"ok\" is a neutral expression that doesn\\'t convey strong emotions, indicating a lukewarm or average opinion about the movie.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 59, 'total_tokens': 93, 'completion_time': 0.056174522, 'prompt_time': 0.00294793, 'queue_time': 0.05543042, 'total_time': 0.059122452}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--981f5844-18ce-4c1f-846a-9a8e2e920880-0', usage_metadata={'input_tokens': 59, 'output_tokens': 34, 'total_tokens': 93})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot = zero_shot_prompt.format_messages(input=\"the movie was ok\")\n",
    "llm_obj.invoke(zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e42655-3761-4970-8f4a-6525dae2df85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
